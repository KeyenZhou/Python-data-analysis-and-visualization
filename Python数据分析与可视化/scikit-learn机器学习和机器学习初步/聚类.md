# 1. 聚类

聚类分析，即聚类，包括自动发现数据中的自然分组，是一项无监督的机器学习任务。与监督学习（类似预测建模）不同，聚类算法只解释输入数据，并在特征空间中找到自然组或群集。
   
聚类分析的所有目标的核心是被群集的各个对象之间的相似程度（或不同程度）的概念。聚类方法尝试根据提供给对象的相似性定义对对象进行分组。聚类分析是一个迭代过程，在该过程中，对所识别的群集的主观评估被反馈回算法配置的改变中，直到达到期望的或适当的结果。
   
 聚类与分类的区别如下表。
 
 |              | **聚类**                                                     | **分类**                                                     |
| ------------ | :------------------------------------------------------------ | :------------------------------------------------------------ |
| **核 心**    | 将数据分成多个组                                             | 从已经分好的数据中去学习，将新数据放到已经分号的组中去       |
| **学习类型** | 无监督，无需标签进行训练                                     | 有监督，需要标签进行训练                                     |
| **典型算法** | K-means，DBSCAN，层次聚类，光谱聚类                          | 决策树，贝叶斯，逻辑回归                                     |
| **算法输出** | 聚类结果不确定，同样的聚类结果，<br>根据业务需求的不同,可能是一个好结果，也可能是一个坏结果 | 分类结果是确定的 ，分类的优劣是客观的 <br>不是根据业务需求或算法需求决定 |

下面结合实例，简单介绍如何使用K-means、DBSCAN算法进行聚类分析。 

# 2. K-means算法

K-Means算法，K代表类别数量，Means代表每个类别内样本的均值，所以又叫K均值算法，是一种常见的聚类算法。算法会将数据集分为K个簇，每个簇使用簇内所有样本均值来表示，将该均值称为“质心”。

K-Means算法以距离作为样本间相似度的度量标准，将距离相近的样本分配至同一个类别。样本间距离的计算方式可以是欧氏距离，曼哈顿距离，余弦相似度等，K-Means算法通常采用欧氏距离来度量各样本间的距离。

![](./数据集/image%20(15).png)

K-Means步骤：
1. 从样本中选择 K 个点作为初始质心（完全随机）
2. 计算每个样本到各个质心的距离，将样本划分到距离最近的质心所对应的簇中
3. 计算每个簇内所有样本的均值，并使用该均值更新簇的质心
4. 重复步骤 2 与 3 ，直到达到以下条件之一：
    * 质心的位置变化小于指定的阈值（默认为 0.0001）
    * 达到最大迭代次数
    
以下[K-Means算法过程可视化网站](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)，可通过可视化效果展示了K-Means算法的过程。
    
#### 例：航空公司客户价值分析

文件“air_data.csv”中包含某航空公司记录的客户相关信息，文件中共62000多名客户信息，每位客户有44个属性（相关字段含义可参考文件“客户信息属性说明.xls”）。下面使用K-Means算法对客户聚类，进行客户价值分析。


```python
import pandas as pd

air_data = pd.read_csv('/data/bigfiles/air_data.csv')
# 过滤异常数据
# 过滤票价为空的记录
air_data = air_data[air_data['SUM_YR_1'].notnull() & air_data['SUM_YR_2'].notnull()]
# 保留，票价非0的记录，总飞行里程数为0且平均则扣为0的记录也保留（可能为积分兑换）
air_data = air_data[(air_data['SUM_YR_1'] != 0) | (air_data['SUM_YR_2'] != 0)
                      | ((air_data['SEG_KM_SUM'] == 0) & (air_data['avg_discount'] == 0))]
backup_data = air_data.copy()  # 备份数据
air_data.shape
```

一种常见的用户分层模型为LRFMC模型，其通过5个指标进行客户细分：
* L（lifetime）：客户关系长度，代表用户第一次消费算起至今的时间，反映了用户可能的活跃总时间。
* R（recency）：客户最近消费时间，反映了用户留存情况
* F（Frequency）：客户消费频率，反映了用户粘性
* M（Monetary）：客户的消费金额，反映了用户消费能力
* C（costartio）：平均折扣率，代表用户在一定时间内消费的折扣系数，反映了用户对促销的偏好性，也可侧面反映客户价值（折扣率与等级相关）。

本例中使用原始数据，通过如下规则构建LRFMC模型数据集：
$$ \begin{align*}
L=&LOAD\_TIME - FFP\_DATE && \quad(观测窗口的结束时间 - 入会时间)\\
R=&LAST\_TO\_END && \quad(最后一次乘坐飞机距观测窗口结束的时长) \\
F=&FLIGHT\_COUNT && \quad(观测窗口内的飞行次数)\\
M=&SEG\_KM\_SUM && \quad(观测窗口内的总飞行里程)\\
C=&AVG\_DISCOUNT && \quad(平均折扣率)
\end{align*}$$


```python
# 选取指标相关指标
air_data = air_data[['LOAD_TIME', 'FFP_DATE', 'LAST_TO_END', 'FLIGHT_COUNT', 'SEG_KM_SUM','avg_discount']]
# 观察在有效数据中是否存在空值
print(air_data.isnull().sum())
# 时间格式转换并计算L
air_data['L'] = (pd.to_datetime(air_data['LOAD_TIME']) - pd.to_datetime(air_data['FFP_DATE'])).dt.days
# 修改列标签
air_data.columns=['截止日期', '入会日期', 'R', 'F', 'M', 'C', 'L']
# 保留LRFMC数据
air_data = air_data[['R', 'F', 'M', 'C', 'L']]
air_data.head()                                                                                   
```

观察可发现，各特征数据值最大值和最小值间隔较大，因此需对数据进行标准化。


```python
from sklearn.preprocessing import StandardScaler  # 用于数据预处理模块的缩放器

# 缩放处理，对数据按列属性进行scale处理后，每列的数据均值变成0，标准差变为1。
air_data.loc[:,:] = StandardScaler().fit_transform(air_data.loc[:,:])
air_data.head() 
```

数据处理完毕，建立模型进行聚类。这里设置n_clusters=5，分5类。因为K-Means的初始中心点是比较随机的，所以当数据量较大可能会导致最后的分群结果略有不同，如果希望每次运行代码的时候可以让结果都是一样的，可以在模型中传入random_state参数。


```python
from sklearn.cluster import KMeans
import numpy as np

k_means_model = KMeans(n_clusters=5, random_state=5) # 实例化KMeans模型，分5类
k_means_model.fit(air_data)    # 模型训练
# 查看聚类中心
print(k_means_model.cluster_centers_)
# 查看随机30个样本对应的类别
print(k_means_model.labels_[np.random.randint(0, 62000, 30)])
# 对不同的类包含数据进行频数计数
cnt = pd.Series(k_means_model.labels_).value_counts()  # 对不同的类包含数据进行频数计数
print(cnt)
```

可以通过对聚类结果可视化来进行分析。


```python
import matplotlib.pyplot as plt


# 组织结果集
cc = pd.DataFrame(k_means_model.cluster_centers_)
result = pd.concat([cc, cnt], axis=1)
result.columns = list(air_data.columns) + ['cluster_num']
# 准备绘制雷达图的数据，头尾呼应
draw_data = pd.concat([cc, result['R']], axis=1)
print(result)
# 图形化分类结果
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, polar=True)
center_num = draw_data.values
feature = ['R', 'F', 'M', 'C', 'L']
N = len(feature)
for i, v in enumerate(center_num):
    # 设置雷达图的角度，用于平分切开一个圆面
    angles = np.linspace(0, 2 * np.pi, N, endpoint=False)
    # 为了使雷达图一圈封闭起来，需要下面的步骤
    center = np.concatenate((v[:-1], [v[0]]))
    angles = np.concatenate((angles, [angles[0]]))
    # 绘制折线图
    ax.plot(angles, center, 'o-', linewidth=2, label=f'number of  cluster {i + 1}: {result.values[i, -1]:.0f}')
    # 填充颜色
    ax.fill(angles, center, alpha=0.25)
    # 添加每个特征的标签
    ax.set_thetagrids(angles[:-1] * 180 / np.pi, feature, fontsize=15)
    # 设置雷达图的范围
    ax.set_ylim(draw_data.values.min() - 0.1, draw_data.values.max() + 0.1)
    # 添加标题
    plt.title('Customer Cluster', fontsize=20)
    # 添加网格线
    ax.grid(True)
    # 设置图例
    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0), ncol=1, fancybox=True, shadow=True)
plt.show()
```

从雷达图可以看出：
* 客户群4（红色）：这类客户F、M都很高，C、L也不低，是航空公司的高价值客户，属于重要保持客户。
* 客户群1（蓝色）：这类客户C很高，R较高，F、M都很低，但L也较低，说明为新会员，属于重要发展客户。
* 客户群5（紫色）：这类客户L高，C、M、F较低，R较高，可能是流失的老会员，属于重要挽留客户。
* 客户群2（橘色）：这类客户R高，其他指标均较低，可能是“季节型客户”等，属于一般发展客户。
* 客户群3（绿色）：这类客户乘各方面的数据都比较低，属于低价值客户


```python
# 聚类结果写入保存
backup_data['Cluster'] = k_means_model.labels_
backup_data['Cluster'] = backup_data['Cluster'].map({0:'重要发展客户' , 
                                                     1:'一般发展客户', 
                                                     2:'低价值客户', 
                                                     3:'重要保持客户', 
                                                     4:'重要挽留客户'})
backup_data[['MEMBER_NO', 'Cluster']]
```

# 2. DBSCAN算法

DBSCAN (Density-Based Spatial Clustering of Applications with Noise)是一种以密度为基础的空间聚类算法，可以用密度的概念剔除不属于任意类别的噪声点。该算法将簇定义为密度相连的点的最大集合，将具有足够密度的区域划分为簇，并可以发现任意形状的簇。

和K-Means算法相比，DBSCAN最大的不同就是不需要输入类别数k，可以发现任意形状的聚类簇，它在聚类的同时还可以找出异常点。如果所有簇足够密集，并且它们被低密度区域很好地分隔，DBSCAN将获得较好的效果。
<img src="https://www.educoder.net/api/attachments/3668347?type=image/png" style="zoom:100%;">

以下[DBSCAN算法过程可视化网站](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)，可通过可视化效果展示了DBSCAN算法的过程。

#### 例：利用DBSCAN算法对scikit-learn生成的随机样本进行聚类。

使用make_circles()创建随机数据集。


```python
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from sklearn.datasets import make_circles
from sklearn.datasets import make_blobs

# Sklearn中的make_circles方法生成训练样本
coord_1, target_1 = make_circles(n_samples=500, noise=0.1, factor=0.2)
centers = [[2, 2], [-2, -2], [2, -2]]
coord_2, target_2 = make_blobs(n_samples=500, centers=centers, cluster_std=0.4, random_state=0)
coord=np.concatenate((coord_1,coord_2),axis=0)

# 绘制生成点的散点图
coord_data = pd.DataFrame(coord, columns=['X', 'Y'])
sns.relplot(x='X', y='Y', data=coord_data,s=100)
plt.title('data by make_circles()')
plt.show()
```

遍历参数取值，通过轮廓系数，查找最优参数。轮廓系数的值是介于\[-1,1\] ，越趋近于1代表内聚度和分离度都相对较优。


```python
import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score

for eps in [i / 10 for i in range(2, 6)]:
    for min_samples in range(7,10):
        print(f'eps {eps}')
        print(f'min samples {min_samples}')

        dbscan_test = DBSCAN(eps=eps, min_samples=min_samples)
        labels_test = dbscan_test.fit_predict(coord_data)
        score = silhouette_score(coord_data, labels_test)

        print(f'clusters present: {np.unique(labels_test)}')
        print(f'clusters sizes: {np.bincount(labels_test + 1)}')
        print(f'Silhouette Score: {score}')
        print()
```

使用挑选的参数，构建DBSCAN算法对数据集进行聚类分析。


```python
dbscan_model = DBSCAN(eps=0.5, min_samples=7)
labels = dbscan_model.fit_predict(coord_data)
coord_data['clustdbscan'] = labels
# 绘制散点图，观察聚类结果
sns.relplot(x='X', y='Y', data=coord_data,hue='clustdbscan',style='clustdbscan',s=100)
plt.title('clusters by dbscan')
plt.show()
```

没有-1类，意味着无异常数据。可修改参数，观察结果的区别。


```python
dbscan_model_new = DBSCAN(eps=0.4, min_samples=7)
labels_new = dbscan_model_new.fit_predict(coord_data)
coord_data['clustdbscan_new'] = labels_new
# 绘制散点图，观察聚类结果
sns.relplot(x='X', y='Y', data=coord_data,hue='clustdbscan_new',style='clustdbscan_new',s=100)
plt.title('clusters by dbscan_new')
plt.show()
```
