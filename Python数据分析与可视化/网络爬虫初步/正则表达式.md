# 5. 正则表达式

爬虫所获取的网页源代码中的很多内容是我们不需要的，可以使用正则表达式对网页源代码的字符串进行匹配，提取出需要的数据。  
爬虫程序经常需要从大段文本中提取信息，正则表达式是提取信息最直接的方法之一。正则表达式(Regular Expression，RE)是一串字符串，可以用于匹配一段有规律的字符串信息，可以用来检查、提取和替换一个字符串中符合某种规律的子串。  

例如一个网页上有多个用户的邮箱地址，想提取网页上全部的邮箱时，可以构造一个正则表达式。我们知道邮箱的基本格式为“名称@域名”，“@”符号必须存在且只出现一次，假设不考虑中文用户名和中文域名，用户名由只允许英文字母、数字、下划线、英文句号、以及中划线组成，合法的域名的规律为“[N级域名][三级域名.]二级域名.顶级域名”，例如“cn”、“edu.cn”、“whut.edu.cn”、“mail.whut.edu.cn”等。那么就可以构造如下的正则表达式用于查找和提取网页上的所有的合法邮箱数据。
^[a-zA-Z0-9_-]+@[a-zA-Z0-9_-]+(\.[a-zA-Z0-9_-]+)+$
所以，在学习爬虫程序之前，需要先掌握正则表达式的基本符号和利用正则表达式提取信息的基本方法。组成正则表达式的字符分为两种基本类型：普通字符和元字符。普通字符包含所有大写和小写字母、所有数字、所有标点符号和一些其他符号。例如 'A', 'a', 或者 '0'，都是最简单的正则表达式，它们就匹配自身。可以拼接普通字符，如 last 匹配字符串 'last'。 

## 5.1 基本符号

### 1. 特殊字符

特字符是指在正则表达式中具有特殊含义的专用字符，可以用来规定其前导字符在目标对象中的出现模式，使正则表达式具有处理能力。常用的特殊字符的含义如下表：

| 字符            | 描述     | 
| :--------------- | :--------|
| .	 | (点) 在默认模式，匹配除换行符（\n、\r）之外的任何单个字符，相当于 [^\n\r] |
| ^	 | (插入符号) 匹配字符串的开始位置 |
| \$	 |  匹配字符串的结尾或者新的一行前面的字符串的结尾， 例如：foo$匹配 'foo' |
| [] | 	字符集合，范围内的所有字符都可以被匹配。<br />例如 [amk] 匹配 'a'， 'm'， 或者 'k'。 [a-z] 匹配任何小写ASCII字符， [0-5][0-9] 将匹配从 00 到 59 的两位数字 |
| |	 | A|B， A 和 B 可以是任意正则表达式，匹配 A 或者 B，任意个正则表达式可以用 '|' 连接 |
| (...) | 	（组合），匹配括号内的任意正则表达式，并标识出组合的开始和结尾。 |
| \	 | 转义字符，使后面一个元字符失去特殊意义，匹配字符本身 |

### 2. 限定符

限定符用来指定正则表达式的一个给定组件必须要出现多少次才能满足匹配。有 * 或 + 或 ? 或 {n} 或 {n,} 或 {n,m} 共6种。
正则表达式的限定符有：

| 字符            | 描述     | 
| :--------------- | :--------|
| *	| 匹配前面的子表达式零次或多次。例如，ab* 能匹配 "a" 以及 "abb"，* 等价于{0,}。|
| +	| 匹配前面的子表达式一次或多次。例如，'ab+' 能匹配 "ab" 以及 "abb"，但不能匹配 "a"，+ 等价于 {1,}。|
| ?	| 匹配前面的子表达式零次或一次。例如，ab? 会匹配 'a' 或者 'ab'，但不能匹配 "abb"，? 等价于 {0,1}。|
| \*? <br /> \+? <br /> \??	| '*', '+'，和 '?' 修饰符都是贪婪的，它们在字符串进行尽可能多的匹配。<br />在修饰符之后添加 ? 将使样式以非贪婪方式或者最简方式进行匹配； 匹配尽量少的字符。 <br />例如：<.*?> 仅仅匹配 '<a>'|
| {m}	| m 是一个非负整数。确定匹配前面的子表达式 m 次。<br />例如，'o{2}' 能匹配 "food" 中的两个 o，但不能匹配 "Bob" 中的 'o'|
| {m,n}	| m 和 n 均为非负整数，其中m <= n。最少匹配 m 次且最多匹配 n 次。<br />例如，a{3,5} 将匹配 3 到 5个 'a'。忽略 m 意为指定下界为0，忽略 n 指定上界为无限次。 <br />例如 a{4,}b 将匹配 'aaaab' 或者1000个 'a' 尾随一个 'b'，但不能匹配 'aaab'。<br />逗号不能省略，否则无法辨别修饰符应该忽略哪个边界。|
| {m,n}?	| 前一个修饰符的非贪婪模式，只匹配尽量少的字符次数。<br />例如，对于 'aaaaaa'， a{3,5} 匹配 5个 'a' ，而 a{3,5}? 只匹配3个 'a'。|

下面列出由 '\' 和一个字符组成的特殊序列。

| 字符            | 描述     | 
| :--------------- | :--------|
| \A	|只匹配字符串开始位置。|
| \b	|匹配单词开始或结尾的位置的空字符串。|
| \B	|匹配空字符串，但不能在词的开头或者结尾。|
| \d	|匹配任何Unicode十进制数|
| \D	|匹配任何非十进制数字的字符|
| \s	|匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]|
| \S	|匹配任何非空白字符。等价于 [^ \f\n\r\t\v]|
| \w	|匹配字母、数字、数字和下划线。等价于 [A-Za-z0-9_]|
| \W	|匹配当前区域中既非字母数字也非下划线的字符。|
| \Z	|只匹配字符串结尾。|

### 3. 转义字符

绝大部分Python标准转义字符也可以是正则表达式的组成部分。

| 字符            | 描述     | 
| :--------------- | :--------|
| \cx	| 匹配由x指明的控制字符| 
| \f	| 匹配一个换页符。等价于 \x0c 和 \cL| 
| \n	| 匹配一个换行符。等价于 \x0a 和 \cJ| 
| \r	| 匹配一个回车符。等价于 \x0d 和 \cM| 
| \t	| 匹配一个制表符。等价于 \x09 和 \cI| 
| \v	| 匹配一个垂直制表符。等价于 \x0b 和 \cK| 

下面通过一些简单的实例，帮助理解正则表达式的用法。

### 1. \w与\W

\w匹配字母、数字、数字和下划线，\W匹配当前区域中既非字母数字也非下划线的字符。


```python
import re

email = 'vasp@qq.com'
print(re.findall(r'\W', email))           # ['@', '.']，匹配非字母、数字、下划线
print(''.join(re.findall(r'\w', email)))  # vaspqqcom,用join()将结果连接为一个字符串
```

### 2. \s与\S

\s匹配任何空白字符，包括空格、制表符、换页符等，\S匹配任何非空白字符。


```python
import re

poem = """苏幕遮　范仲淹\n
\n
\t\t碧云天，黄叶地，秋色连波，波上寒烟翠。\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　
\n　　　"""
print(''.join(re.findall(r'\S', poem))) 
# 苏幕遮范仲淹碧云天，黄叶地，秋色连波，波上寒烟翠。
```

### 4. \d与\D

\d匹配所有数字字符，\S匹配所有非数字字符。


```python
import re

temp_str = '子曰1：“学2而时习3之，不亦说4乎？有朋5自远方来，不亦乐6乎？'
print(''.join(re.findall(r'\D', temp_str)))  
# 子曰：“学而时习之，不亦说乎？有朋自远方来，不亦乐乎？
```

### 5. \\^ 和\\ \$

'^s'只匹配位于字符串开头的字符串s，'s$'只匹配位于字符串末尾的字符串s。


```python
import re

temp_str = '武汉理工大学位于武汉'
print(re.findall('武汉', temp_str))  # 匹配字符串中的武汉，['武汉', '武汉']
print(re.findall('^武汉', temp_str))  # 只匹配位于字符串开头的武汉，['武汉']
print(re.findall('武汉$', temp_str))  # 只匹配位于字符串末尾的武汉，['武汉']
```

### 6. 点号“.”、星号“*”和问号“?”

一个点号可以匹配除换行符（\n、\r）之外的任何单个字符，相等于 [^\n\r]。包括但不限于英文字母、数字、汉字、英文符号和中文符号等。问号“?”匹配前面的字符0次或1次，星号“*”匹配前面的字符任意多次。
例如：


```python
import re

temp_str = 'abcaaabb'
print(re.findall('a.b', temp_str))  # ['aab']
print(re.findall('a?b', temp_str))  # ['ab', 'ab', 'b']
print(re.findall('a*b', temp_str))  # ['ab', 'aaab', 'b']
print(re.findall('a.*b', temp_str))  # ['abcaaabb']，匹配任意个数的任意字符
print(re.findall('a.*?b', temp_str))  # ['ab', 'aaab']，匹配任意个数的任意字符
```

### 7. 转义字符“\”


```python
import re

temp_str = '\teaching'
print(''.join(re.findall('t', temp_str)))
# 因\t为制表符，匹配不到t

temp_str = '\\teaching'
print(''.join(re.findall('t', temp_str)))  # 因\\t转义，可以匹配t

temp_str = r'\teaching'  # 用 r 对字符串进行转义
print(''.join(re.findall('t', temp_str)))  # 输出t
```

正则表达式“.*” 表示匹配任意个数的任意字符，能匹配多长就匹配多长，称为贪婪匹配；“.?”也表示匹配任意个数人任意字符，但是能匹配多短就匹配多短，称为非贪婪匹配。
'武汉..大学'匹配字符串前2个字符是“武汉”，后面两个字符是“大学”，中间还有2个字符的字符串，中间有多少个字符就用多少个点。

### 8.字符集[]


```python
import re

temp_str = 'abb ahb azb a0b  a6b a9b'
print(re.findall('a[a-z]b', temp_str))  # ['abb', 'ahb', 'azb']
# 中间字符属于a-z的字母就可以匹配
print(re.findall('a[0-9]b', temp_str))  # ['a0b', 'a6b', 'a9b']
# 中间字符属于0-9的数字就可以匹配
print(re.findall('a[abc]b', temp_str))  # ['abb']
# 中间字符只能是abc之一才可以匹配
```

### 9. 分组()

() 表示捕获分组，() 会把每个分组里的匹配的值保存起来。


```python
import re

temp_str = 'vasp@qq.com'
print(re.findall('(\w+)@(\w+).(\w+)', temp_str))  
# [('vasp', 'qq', 'com')]
```

## 5.2 正则表达式的应用

掌握了正则表达式，就可以利用内置re模块中的函数，在网页源代码中提取数据了。下面介绍内个常用的函数：

### 1. findall()函数
re.findall(pattern, string, flags=0)
findall()函数能提取满足正则表达式的所有字符串。


```python
import re
import requests  # 导入requests模块

# 网页头，模拟浏览器行为
headers = {'User-Agent':
           'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.9 Safari/537.36'}
url = 'https://www.shicimingju.com/shicimark/songcisanbaishou.html'
# 浏览器传递参数，'limit': '2'表示只返回前2条数据，修改数字可以得到更多数据
response = requests.get(url=url, timeout=1.0)
text = response.text.replace(' ','')
poem_name = re.findall('《.*?》',text)
# 匹配以《开头，以》结尾，中间包含任意字符的字符串
print(poem_name)
```

可以获得该页面上所有宋词名

['《渔家傲·塞下秋来风景异》', '《醉花阴·薄雾浓云愁永昼》', '《声声慢·寻寻觅觅》', '《念奴娇·赤壁怀古》', '《雨霖铃·寒蝉凄切》', '《浣溪沙》', '《永遇乐·落日熔金》', '《临江仙夜登小阁，忆洛中旧游》', '《水龙吟·次歆林圣予惜春》', '《忆少年·无穷官柳》', '《临江仙·忆昔西池池上饮》', '《绿头鸭·咏月》', '《苏幕遮·碧云天》', '《御街行·纷纷坠叶飘香砌》', '《凤箫吟》', '《薄幸·淡妆多态》', '《喋恋花》', '《浣溪沙》', '《浣溪沙》', '《天门谣·牛渚天门险》']


### 2. search()函数
re.search(pattern, string, flags=0)
search()函数扫描整个字符串，找到并返回匹配样式的第一个满足正则表达式的字符串，使用group()函数取值，匹配不到时返回None。


```python
import re

temp_str = '?vasp@qq.com'
ret = re.search(r'\w', temp_str)
print(ret.group())  # 匹配到时使用group()函数取值，返回字符串'v'
```

### 3. match()函数
re.match(pattern, string, flags=0)
与 search() 函数功能类似，区别是从头开始匹配0个或多个字符，若开头不满足，后面满足正则表达式的字符串也不会被匹配。 如果没有匹配，就返回 None ；


```python
import re

temp_str = '?vasp@qq.com'
ret = re.match(r'\w', temp_str)
print(ret)  # None
```

### 4. sub()函数
re.sub(pattern, repl, string, count=0, flags=0)
返回通过使用 repl 替换在 string 最左边非重叠出现的 pattern 而获得的字符串。 如果样式没有找到，则不加改变地返回 string。 repl 可以是字符串或函数；如为字符串，则其中任何反斜杠转义序列都会被处理。 
元素会自动在其前后创建一些空白。

网络爬虫按照实现的技术和结构可以分为通用网络爬虫、聚焦网络爬虫、增量式网络爬虫和深层网络爬虫等几种类型。在实际的使用过程中，经常是多种类型组合使用。  
1.通用网络爬虫又称为全网爬虫，是百度和谷歌等捜索引擎抓取系统的重要组成部分，主要目的是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份，有非常高的应用价值。通用网络爬虫从互联网中搜集网页，采集信息，这些网页信息用于为搜索引擎建立索引从而提供支持，它决定着整个引擎系统的内容是否丰富，信息是否即时，因此其性能的优劣直接影响着搜索引擎的效果。通用网络爬虫的爬取范围和数量巨大，爬取的是海量数据，对爬行速度和存储空间要求极高，一般采用并行的工作方式。  
2.聚焦网络爬虫是“面向特定主题需求”的一种网络爬虫程序，因此也称为主题网络爬虫。它与通用搜索引擎爬虫的区别在于聚焦爬虫在实施网页抓取时会对内容进行处理筛选，按照预先确定的主题，有选择地进行网页爬取的一种爬虫，尽量保证只抓取与需求相关的网页信息，从而可以极大的节省存储硬件和网络资源，并可以快速获取所需主题的相关数据。一般用户使用的爬虫都是这一种类型。  
3.增量型网络爬虫是指在爬取数据时，只爬取新产生或更新过的页面，对于没有发生变化的页面，则不会爬取，这样可以有效的减少数据下载量，减少时间和空间的开销。  
4.深层网络爬虫是指能爬取那些隐藏在深层网页中的信息的爬虫。所谓深层网页是指那些不能通过静态链接获取、需要提交一些表单才能获得的页面。实际上，互联网上大部分信息都是隐藏在深层网页中的，所以深层网页是主要的爬取对象。深层网络爬虫主要通过爬行控制器、解析器、表单分析器、表单处理器、响应分析器、LVS（Label Value Set：标签/数值集合）控制器、URL表和LVS表等部分构成。


```python

```
